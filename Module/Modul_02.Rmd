---
title: "Module 02: An arrow shows the way"
output: 
  learnr::tutorial:
    progressive: true
    css: "css/style.css"
runtime: shiny_prerendered
---

<a href="https://ki-campus.org/">
<img border="0" alt="KICampusLogo" src="images/KIcampusLogo.png" width="100" height="30" style="float: right">
</a>

```{r setup, include=FALSE}
library(learnr)
library(knitr)
library(ggplot2)
library(dplyr)
library(tidyr)
library(emojifont)
library(openintro)

theme.fom <- theme_classic(22*1.04)
theme.fom <- theme.fom
theme_set(
  theme.fom  
)

library(ggdag)

# DAG, ohne Fehlerterm
co <- data.frame(x=c(0,1), y=c(0,0), name=c("X", "Y"))
DAG1 <- dagify(Y~ X,
                   coords = co) %>% 
  ggdag() + 
  geom_dag_point(colour = c("#0F710B", "#0000FF")) + 
  geom_dag_text(size = 8) +
  theme_dag_blank() +
  geom_dag_edges(arrow_directed = grid::arrow(length = grid::unit(15, "pt"), type = "closed")) +
  geom_text(label = "X - pill\nY - pain reduction", 
            hjust = 1, vjust = 2,
            x = 1, y = 0, size = 7, color = "darkgrey") 

# Beispiel rutschige Straße
co <- data.frame(x = c(0,1,1,2,4), y = c(0.5,0,1,0.5,0.5), name = c("SE", "RA", "SP","WE","SL")) 
DAG_Str <- dagify(SP ~ SE,
                  RA ~ SE,
                  WE ~ RA,
                  WE ~ SP,
                  SL ~ WE,
                  coords = co) %>%
    ggdag() + 
   geom_dag_point(colour = "#301a87") +
  geom_dag_text(size = 5) +
  theme_dag_blank() +
  geom_dag_edges(arrow_directed = grid::arrow(length = grid::unit(15, "pt"), type = "closed")) +
  geom_text(label = "SE - season\nRA - rain\nSP - sprinkler\nWE - wet\nSL - slippery", 
            hjust = 1, vjust = 1,
            x = 4, y = 1, size = 5, color = "darkgrey") 

# DAG 2, mit Fehlerterm
co <- data.frame(x=c(0,1,0,1), y=c(0,0,1,1), name=c("X", "Y", "U_X", "U_Y"))
DAG2 <- dagify(Y~ X,
               X ~ U_X,
               Y ~ U_Y,
                   coords = co) %>% 
  ggdag() + 
  geom_dag_point(colour = c( "darkgrey", "darkgrey","#0F710B", "#0000FF")) + 
  geom_dag_text(size = 7, label =  c(expression(U[X]), expression(U[Y]), "X", "Y"), parse = TRUE) +
  theme_dag_blank() +
  geom_dag_edges(arrow_directed = grid::arrow(length = grid::unit(15, "pt"), type = "closed")) +
  geom_text(label = "X - pill\nY - pain reduction", 
            hjust = 1, vjust = 2,
            x = 1, y = 0, size = 7, color = "darkgrey")

# Funktionen für Beispiel

U_X <- function() sample(c("Yes", "No"),1)
f_Y <- function(x) ifelse(x == "Yes", sample(c("Yes", "No"), 1, prob = c(0.8,0.2)), sample(c("Yes", "No"), 1, prob = c(0.4,0.6)))

# Verteilung Beispiel
d <- crossing(x = 1:10,
              y = 1:10) %>%
  mutate(tablette = c(rep("Yes",50), rep("No", 50)),
         heilung = c(rep(fontawesome('fa-check'), 50 * 0.8),
                     rep(fontawesome('fa-close'), 50 * 0.2),
                     rep(fontawesome('fa-check'), 50 * 0.4),
                     rep(fontawesome('fa-close'), 50 * 0.6)))

pd <- ggplot(d, aes(x = x, y = y, color = tablette)) +
  geom_tile(color = "white", size = .5, aes(fill = tablette), alpha = .2) +
  theme_void() +
  geom_text(family='fontawesome-webfont', size = 8, aes(label = heilung)) +
  scale_color_manual(values = c("#0F710B", "grey80"),
                     name = "") +
  scale_fill_manual( values = c("#0F710B", "grey80")) +
  theme(legend.position = "none") +
  labs(title = "Pain reduction") +
  guides(guide = "none") +
  annotate(geom="text", x=3, y=5.5, label="Took pill",
             color="black", size = 10) +
  annotate(geom="text", x=8, y=5.5, label="Didn't take pill",
           color="black", size = 10)

```

## Learning objectives

In this module, you will learn:

- what cause and effect are;

- the basic of causal graphs: the meaning of an arrow;

- parents and children;

- what a causal model is;

- the difference between observing and doing in the context of causal inference. 


## Cause and effect

Humans have always been thinking about cause and effect -- not just in philosophy, but also in everyday life:

- If I take a pill, will the pain go away?

- Does advertising increase sales?

- Is participation in a certain course worth it?

We can either decide to take a pill, or decide against it -- the pain will go away, or it won't.
Companies can invest more money into advertising, or less -- sales will increase, or they will go down.
You participate in the course or you don't -- your salary will increase, or it (unfortunately) won't.


Thus, can observe all sorts of different values, such as "Yes" and "No" (taking the pill, pain reduction); $0$ &dollar; or $1000$ &dollar; (change in sales, in salary). 

These values will occur with different *probabilities*, which we abbreviate as $Pr$. $Pr(\text{Pill})$ thus is the probability that somebody takes a pill;  $Pr(\text{pain reduction})$ is the probability that the pain disappears.


```{r ursache, echo=FALSE}
question("Let's assume that if you take the pill, the pain will go away. What is cause and what is effect?",
         answer("Taking the pill is the cause, pain reduction is the effect.", correct = TRUE),
         answer("Pain reduction is the cause, the pill is the effect."),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement()
         )
```

## Pills and pain

<!-- Quelle: https://github.com/TabeaG/Uebungsheft-Apps/blob/master/EinfuehrungWkeitInferenz/02_EinfuehrungWkeitInferenz.Rmd -->

<span style="font-size: 13px; font-weight: bold; margin-top: 20px;">
Let's see whether taking the pill helps!
</span>

<img src="images/Pillen.jpg" alt="Pillenpackung" width="50%" height="50%">
<!-- style="padding-left:50px;" -->
<span style="font-size: 10px;"><br>
Quelle: [https://pixabay.com/illustrations/jar-pills-medicine-bottle-2338584/](https://pixabay.com/illustrations/jar-pills-medicine-bottle-2338584/)
</span>

<span style="font-size: 13px; font-weight: bold; margin-top: 20px;">
Do you want to take the pill? <br> </span>
<span style="font-size: 13px; ">
Choose one of the buttons. You can try multiple times to see what happens.
</span> 

```{r, context="render", echo=FALSE}
actionButton("Pill", "Take pill", class="btn action-button", style="color: #FFF; background-color: #301a87; border-color: #301a87; order-radius: 10px; border-width: 2px")
```
```{r, context="render", echo=FALSE}
actionButton("nPill", "Don't take pill", class="btn action-button", style="color: #FFF; background-color: #301a87; border-color: #301a87; order-radius: 10px; border-width: 2px")
```


```{r, context="render", echo=FALSE}
htmlOutput("ergebnis")
```

```{r, context="server"}
values <- reactiveValues()
values$text <- ""
values$versuch <- 0

p.tablette <- observeEvent(input$Pill, {
  values$versuch <- values$versuch + 1
  heilung <- sample(c("Yes", "No"), 1, prob = c(0.8,0.2))
  ergebnis <- ifelse(heilung == "Yes", paste0("<span style='color: green'>", values$versuch, ". attempt: </span> You took the pill and the pain went away."), paste0("<span style='color: green'>", values$versuch, ". attempt: </span> You took the pill but the pain did not go away."))
  
output$ergebnis <- renderText({
          ergebnis
        })
  
})
p.ktablette <- observeEvent(input$nPill, {
  values$versuch <- values$versuch + 1
  heilung <- sample(c("Yes", "No"), 1, prob = c(0.4,0.6))
  ergebnis <- ifelse(heilung == "Yes", paste0("<span style='color: green'>", values$versuch, ". attempt: </span> You did not take the pill, yet the pain went away."), paste0("<span style='color: green'>", values$versuch, ". attempt: </span> You did not take the pill and the pain did not go away."))
  
output$ergebnis <- renderText({
          ergebnis
        })
  
})
```

<br>


##

The properties we considered are, on an abstract level, variables. For example: 

- $X$: Taking a pill, Yes or No.

- $Y$: Pain reduction, Yes or No.

The so-called distribution of a variables describes the probabilities with which different values occur.

A variable $X$ is called a **cause** of $Y$, when the value of the **effect** $Y$ is changed by $X$, in other words $Y$ depends on $X$.

If you have tried both taking the pill and not taking it multiple times, you could observe that the pill often (but not always) leads to a pain reduction.
Furthermore, sometimes the pain went away even without pill.

Here are the underlying probabilities:

- $Pr(\text{Pain reduction when pill was taken})=0.8=80\%$<br>
  and thus:
  $Pr(\text{No pain reduction when pill was taken})=1-0.8=0.2=20\%$

- $Pr(\text{Pain reduction when no pill was taken})=0.4=40\%$ <br>
  an thus:
  $Pr(\text{No pain reduction when no pill was taken})=1-0.4=0.6=60\%$

We can also depict this in a probability tree diagram, here assuming that half of the people do take the pill:

```{r baum1, echo=FALSE, fig.align='center', out.width='80%'}
treeDiag(c("Pill?","Pain reduction?"), 
         c(0.5,0.5),
         list(c(0.8,0.2), 
              c(0.4,0.6)),
         c("Yes", "No"),
         c("Yes","No"), 
         showSol = FALSE)
```


## Causal graphs

Alternatively, we could say that the distribution of $Y$ (pain reduction) *listens to* $X$ (taking the pill).
We can visualize this in a very simple graph:


```{r DAG1, echo=FALSE, fig.align='center', out.width='60%'}
plot(DAG1)
```

In such a **graph**, the variables <green>Pill</green> und <blue>Pain reduction</blue> are so-called **nodes**. 
The **arrow** $\rightarrow$ between $\color{green}{X}$ and $\color{blue}{Y}$ is a so-called directed **edge** and indicates a causal dependence.


$\color{green}{X} \rightarrow \color{blue}{Y}$ also means that the value of $\color{green}{X}$ is not causally affected by $\color{blue}{Y}$. 
Thus, <blue>pain reduction</blue> does not retroactively change <green> pill</green>: $$\color{green}{\text{Taking a pill}} \not\leftarrow \color{blue}{\text{Pain reduction}}.$$

<br>

<img src="images/LichtSchalter.jpg" alt="Lichtschalter" width="50%" height="50%">
<!-- style="padding-left:50px;" -->
<span style="font-size: 10px;"><br>
Quelle: [https://pixabay.com/illustrations/switch-lightbulb-idea-inspiration-4539115/](Quelle: https://pixabay.com/illustrations/switch-lightbulb-idea-inspiration-4539115/)
</span>

```{r modell, echo=FALSE}
question("Which causal graph describes the relationship between light switch and light bulb?",
         answer("$\\text{Light bulb} \\rightarrow \\text{Light switch}$"),
         answer("$\\text{Light switch} \\rightarrow \\text{Light bulb}$", correct = TRUE, message = "Light switch on or off is the cause of the effect, light bulb on or off. If something breaks, the light bulb would remain switched off even if the switch is on. But without backcoupling, the switch doesn't turn off just because the light bulb stopped working."),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement()
         )
```

## Children and parents

Some people believe that children listen to their parents.
The nice thing about the abstract world of causal graphs is that here this is indeed the case.


Variables (nodes), into which an arrow points, are called **children** of those variables, from which the arrows exist.
Those variables are in turn called **parents**: $\text{Parent} \rightarrow \text{Child}$. 
Above, <blue>pain reduction</blue> is a child of <green>pill</green> &ndash; conversely <green>pill</green> is parent of <blue>pain reduction</blue>.
So in causal graphs, children do listen to their parents.

Here is another example: a causal graph that describes, how a road might end up slippery.
The probability of rain depends on the season.
The season also determines whether the sprinkler is switched on.
Both rain and season can make the street wet.
Once the street is wet, it may turn slippery:


```{r DAG_Str, echo=FALSE, fig.align='center', out.width='85%'}
plot(DAG_Str)
```

Quelle: [Mohan und Pearl (2012)](https://ftp.cs.ucla.edu/pub/stat_ser/uai12-mohan-pearl.pdf)

```{r eltern, echo=FALSE}
question("Which variable(s) are the parents of *wet* (WE)?",
         answer("There are none."),
         answer("Season (SE)."),
         answer("Sprinkler (SP) and rain (RA).", correct = TRUE,  message = "Wet depends on sprinkler and rain."),
         answer("Slippery (SL)."),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement()
         )
```

```{r kinder, echo=FALSE}
question("And which variable(s) are the children of wet?",
         answer("There are none."),
         answer("Season (SE)"),
         answer("Sprinkler (SP) and rain (RA)."),
         answer("Slippery (SL).", correct = TRUE , message = "Slippery depends on wet."),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement()
         )
```

## Causal models

The **causal model** underlying the simple graph $\color{green}{X} \rightarrow \color{blue}{Y}$ consists of two assignments:

- $\color{green}{X} = U_{\color{green}{X}}$
- $\color{blue}{Y} = f_{\color{blue}{Y}}(\color{green}{X},U_{\color{blue}{Y}})$

Where $U_{\color{green}{X}}$ und $U_{\color{blue}{Y}}$ are unknown causes (in statistics often called error terms) of $\color{green}{X}$ and $\color{blue}{Y}$, and $f_{\color{blue}{Y}}(\color{green}{X},U_{\color{blue}{Y}})$ is the function, the mechanism, through which $\color{blue}{Y}$ is assigned a value based on $\color{green}{X},U_{\color{blue}{Y}}$. 

In the example
$$\color{green}{\text{Pill}} \rightarrow \color{blue}{\text{Pain reduction}}$$ 
$U_{\color{green}{\text{Pill}}}$ contains the unknown (potentially random) reasons that lead somebody to take the pill (or not), and $U_{\color{blue}{\text{Pain reduction}}}$ contains any unknown (potentially random) additional reasons why the pain may go away, with or without taking the pill.


Here, we will assume that $U_{\color{green}{X}}$ and $U_{\color{blue}{Y}}$ are completely independent of each other.

These so-called errors can be added to the graph, but they are often omitted to avoid crowding of the graph. 


```{r DAG2, echo=FALSE, fig.align='center', out.width='60%', warning=FALSE}
plot(DAG2)
```


Let us assume you flip a coin (`ux()`) to determine whether you will take the pill or not, and the following applies to pain reduction (`fy()`):

- $Pr(\text{Pain reduction, if pill was taken})=0.8$ 

- $Pr(\text{No pain reduction, if pill was taken})=1-0.8=0.2$

- $Pr(\text{Pain reduction, if no pill was taken})=0.4$ 

- $Pr(\text{No pain reduction, if no pill was taken})=1-0.4=0.6$

Let us simulate this situation multiple times by pressing `Run Code` and observe which value the variables take on:


```{r sim, exercise=TRUE}
x <- U_X()
cat("Pill? ", x, "\n")
y <- f_Y(x)
cat("Pain reduction? ", y, "\n")
```

```{r sim-hint}
# Here is the R code of the underlying functions:
U_X <- function() sample(c("Yes", "No"),1)

f_Y <- function(x) ifelse(x == "Yes", 
                          sample(c("Yes", "No"), 1, prob = c(0.8, 0.2)), 
                          sample(c("Yes", "No"), 1, prob = c(0.4, 0.6)))
```


## Observation

If $100$ people flip a coin to determine whether they will take the pill or not, we expect on average that $50$ will take the pill (green) and of these,  $50 \times 0.8 = 40$ will experience a pain reduction (<i class="fa fa-check" aria-hidden="true"></i>). The other $50-40=10$ won't (<i class="fa fa-close" aria-hidden="true"></i>). 
Of the $50$ who do not take the pill (grey), $50 \times 0.4 = 20$ will experience a pain reduction (<i class="fa fa-check" aria-hidden="true"></i>) and the remaining $50-20=30$ won't (<i class="fa fa-close" aria-hidden="true"></i>):

```{r pd, echo=FALSE, fig.align='center', out.width='85%'}
plot(pd)
```

All in all, we expect that on average $40 + 20 = 60$ of $100$ people experience a pain reduction, as long as $U_{\color{green}{\text{Pill}}}$ is randomly Yes or No with $Pr(\color{green}{\text{Pill}})=0.5$. 

We only **observe** which value the cause $\color{green}{X}$ takes on. 

```{r handeln, echo=FALSE}
question("What happens if we intervene so that taking the pill is no longer random -- but instead we determine that everybody has to take the pill?",
         answer("The same number of people will experience a pain reduction."),
         answer("More people will experience a pain reduction.", correct = TRUE, message = "Thanks to the intervention, it is no longer $Pr(\\color{green}{\\text{Pill}})=0.5$ but $Pr(\\color{green}{\\text{Pill}})=1$. Since the pill helps in $80\\%$ of the cases, we can expect on average a pain reduction for $100 \\times 0.8 = 80$ out of $100$ people."),
         answer("Fewer people will experience a pain reduction."),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement()
         )
```

## Interventions

During an **intervention**, we act and actually do something.
The causal model no longer says:


$$\color{green}{X} = U_{\color{green}{X}}$$
but instead, for example -- if we force everyone to take the pill:

$$\color{green}{X} = 1$$

with $\color{green}{X} = \cases{1: \quad \text{Pill} \\ 0: \quad \text{No pill}}$.

To formalize the difference between observation and intervention, there is a distinct operator to indicate an operation: $do(\cdot)$ (as in "to do something").
For example, to say that we *force* everybody to take the pill, we can write  $do(\color{green}{X} = 1)$.

```{r do0, echo=FALSE}
question("How can we describe an intervention that leads to nobody taking the pill?",
         answer("$do(\\color{green}{X} = 0)$", correct = TRUE,  message = "$do(\\cdot)$ indicates an action, $\\color{green}{X} = 0$ indicates that nobody takes the pill."),         
         answer("$do(\\color{green}{X} = 1)$"),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement()
         )
```

## Reverse causality

If the suspected cause is in reality the effect, and conversely if the suspected effect is in reality the cause, we encounter the problem of **reverse causality**. We assume $A \rightarrow B$, but in reality $B \rightarrow A$.

We differentiate between cause and effect on the basis of substantive, theoretical considerations.
Time can help to determine what is going on (cause precedes effect), and so can experiments (Module 8).
Both are part of the [Bradford-Hill-criteria](https://journals.sagepub.com/doi/pdf/10.1177/003591576505800503) for causality:

- Strength: causality is more plausible if the association is strong (e.g., high correlation coefficient) and statistically significant.
- Consistency: causality is more plausible when the association is found repeatedly.
- Specificity: causality is more plausible if there are no alternative explanations.
- Temporality: causality is more plausible if the effect comes after the cause. 
- Gradient: causality is more plausible when a larger value of the cause is associated with a larger value of the effect.
- Plausibility: causality is more plausible when there is a substantively plausible mechanism connecting cause and effect.
- Coherence: causality is more plausible if it is aligned with known facts and theories.
- Experiment: causality is more plausible if there is experimental evidence.
- Analogy: causality is more plausible if there are known similar pairs of cause and effect.


## Outlook

Causal inference helps us to investigate differences in the distribution of the effect $\color{blue}{Y}$, depending on whether $\color{green}{X}$ was simply observed or actually determined by an intervention ($do(\color{green}{X})$).

This *causal ladder* is part of the next module.

<img src="images/Leiter.png" alt="Lichtschalter" width="50%" height="50%">
<!-- style="padding-left:50px;" -->
<span style="font-size: 10px;"><br>
Quelle: [https://pixabay.com/vectors/good-girls-cloud-star-ladder-2204244/](Quelle: https://pixabay.com/vectors/good-girls-cloud-star-ladder-2204244/)
</span>

## Note


This course was supported by a grant from the German Federal Ministry of Education and Research, grant number 16DHBQP040.


![](images/csm_Logo-BMBF.jpg)
