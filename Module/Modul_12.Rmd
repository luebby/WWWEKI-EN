---
title: "Module 12: Interrogating Data in Practice"
output: 
  learnr::tutorial:
    progressive: true
    css: "css/style.css"
runtime: shiny_prerendered
---

<a href="https://ki-campus.org/">
<img border="0" alt="KICampusLogo" src="images/KIcampusLogo.png" width="100" height="30" style="float: right">
</a>

```{r setup, include=FALSE}
library(ggplot2)
library(ggdag)
library(ggraph)
theme.fom <- theme_classic(22*1.04)
theme.fom <- theme.fom
theme_set(
  theme.fom  
)

# coordCof <- list(
#   x = c(coffee = 0, miscarriage = 2, nausea = 0.5, U = 1.5),
#   y = c(coffee = 1, miscarriage = 1, nausea = 0, U = 0))
# 
# dagCof <- dagify(coffee ~ nausea,
#                 nausea ~ U,
#                 miscarriage ~ U + coffee,
#                 coords = coordCof,
#                 exposure = "coffee",
#                 outcome = "miscarriage") 
# 
# p1 <- ggdag(dagCof, text_col = "blue", node = FALSE) + theme_dag_blank() 

p1 <- DiagrammeR::grViz("
digraph {
rankdir = LR;
ranksep = 0.7;
 graph []
 node [shape = circle fontcolor = black fontname = Poppins fontsize = 6 style = filled]
   A [label = 'Coffee consumption' fillcolor = '#0F710B' fontcolor = white]
   B [label = '  Miscarriage  ' fillcolor = '#0033cc' fontcolor = white]
   C [label = '    Nausea    ']
   U [label = '         U        ']
 edge [minlen = 2]
  A -> B      [penwidth = .2]
  C -> A      [penwidth = .2]
  U -> {B; C} [penwidth = .2]
{rank = same; A; C}
{rank = same; B; U}
}
")


# coordLif <- list(
#   x = c(robust = 0, society = 0, five = 1, seventy = 2),
#   y = c(robust = 2, society = 0, five = 1, seventy = 1))
# dagLif <- dagify(five ~ robust + society,
#                 seventy ~ five + robust + society,
#                 exposure = "society",
#                 outcome = "seventy",
#                 labels = c("robust" = "Intrinsic\n robustness",
#             "society" = "Type of society",
#             "five" = "Surviving until age 5",
#             "seventy" = "Surviving until age 70"),
#                 coords = coordLif)  
# p2 <- ggdag(dagLif, text = FALSE, text_col = "blue", use_labels = "label", label_col = "blue") + 
#   theme_dag_blank()

p2 <- DiagrammeR::grViz("
digraph {
rankdir = LR;
 graph []
 node [shape = circle fontcolor = black fontname = Poppins fontsize = 11 style = filled]
   A [label = 'Intrinsic Robustness']
   B [label = '  Type of Society  ' fillcolor = '#0F710B' fontcolor = white]
   C [label = '    Surviving until age 5    ']
   D [label = '    Surviving until age 70    ' fillcolor = '#0033cc' fontcolor = white]
 edge [minlen = 2]
   {A; B} -> {C; D} [penwidth = .5]
        C -> D      [penwidth = .5]
}
")


library(learnr)
library(mosaic)
```

## Learning objectives

In this module you will learn:

- what critical data interrogation can look like in practice, and

- what else there is to learn about causal inference beyond the basics.


## Correlation and causality


Correlation does not imply causality &ndash; and no correlation does not imply no causality.

[Bueno de Mesquita and Fowler (2021)](https://press.princeton.edu/books/paperback/9780691214351/thinking-clearly-with-data) put it like this:

$$
Observed \, correlation = Causal\,effect + Bias + Noise
$$

We hope that this course with its examples has helped you think more clearly about systematic *bias* and how it can be addressed.

*Noise* arises from additional (random, unsystematic) sampling variation and is a topic that is covered in more depth in many statistic courses.

## The problem with simplified examples

In this course, you have learned how to define causal effects and how to use causal graphs to map assumptions and infer valid conclusions *under those assumptions*.

But all graphs you saw were highly simplified and contained only few variables.
Reality, of course, looks much more complex &ndash; graphs can contain hundreds of variables, including often ones that are hard to measure or even unobservable.

Even worse, in many situations, we simply do not know what the underlying causal graph looks like.


```{r unsicher, echo=FALSE}
question("Suppose we do not know the true underlying causal graph with certainty, and yet we want to infer causal effects from observational data. Can we still be fully confident that our inferences are correct?",
  answer("Yes."),
  answer("No.", correct = TRUE, message = "Uncertainty about the causal graph leads to uncertainty about whether our inferences are correct. For example, we often cannot rule out the possibility that additional unobserved confounders are biasing our results."),
  allow_retry = TRUE,
  correct = random_praise(),
  incorrect = random_encouragement()
)
```

## Perfect is the enemy of good

But that is no reason to throw in the towel!

Conclusions are always subject to certain uncertainties. 
Even if you know the underlying causal network perfectly well, random noise can still lead to wrong results. 
And even highly complex scientific models are always a simplified representation of reality.


***

***Note:*** In her book ["Idealization and the Aims of Science"](https://www.angelapotochnik.com/idealization.html), philosopher of science Angela Potochnik deals at length with the central role that simplifications play in science -- even in hard sciences like physics. 

***

Even if we do not know the full causal graph, knowledge of the fundamental causal structures helps us to critically question causal inferences and to identify possible biases.


## Example 1: Coffee and miscarriages

Observational studies report a correlation between coffee in pregnancy and miscarriages.
A causal effect is not necessarily implausible here: caffeine can cross the placenta in pregnant women.
That's why it's often recommended to avoid coffee (and other caffeinated beverages) altogether during pregnancy.
But is there really a causal effect that justifies this recommendation?

Coffee consumption during pregnancy depends on many factors.
For example, especially in the first trimester, many women suffer from nausea, which makes coffee a lot less enjoyable.

Furthermore, another line of studies suggests that nausea and vomiting in pregnancy are *negatively* correlated with miscarriage risk.
One possible explanation is that the nausea is caused by hormones that are abundant in a healthy pregnancy.


```{r kaffee, echo=FALSE}
question("What fundamental causal structure does this imply between coffee, nausea, and miscarriage?",
  answer("A chain"),
  answer("A fork", correct = TRUE, message = "Nausea influences coffee consumption, nausea correlates with miscarriage risk. Thus, nausea could be a confounder or at least on a confounding pathway where an unobserved variable (e.g., hormones) influences both nausea and miscarriage risk."),
  answer("An inverted fork"),
  allow_retry = TRUE,
  correct = random_praise(),
  incorrect = random_encouragement()
)
```

## Coffee graph

<center>
```{r p1, echo=FALSE, out.width="40%"}
p1
```
</center>

Studies that adjust for nausea as a variable on a potentially confounding pathway <nobr>($Coffee \leftarrow Nausea \leftarrow U \rightarrow Miscarriage$)</nobr> tend to find weaker associations between coffee consumption and miscarriage risk.

The idea that nausea is on a confounding pathway is also supported by the fact that studies overall find less consistent associations between miscarriage and consumption of other caffeinated beverages (e.g., tea or cola).
While these contain caffeine, they are often found to be less revolting by pregnant women suffering from nausea.

All things considered, the [American College of Obstetricians and Gynecologist (2020)](https://www.acog.org/clinical/clinical-guidance/committee-opinion/articles/2010/08/moderate-caffeine-consumption-during-pregnancy) concludes that moderate caffeine consumption (less than 200mg per day) does not appear to be a risk factor.
At this point in time, no firm conclusion can be drawn regarding larger doses of caffeine in pregnancy.

***

***Note:*** The connections between coffee, nausea, and miscarriages is discussed in more detail in the book "Expecting Better" by economist Emily Oster.

***


## Example 2: Life expectancy in hunter-gatherer societies

Here is an example that has already come up in the interview with Richard McElreath.

Consistent evidence suggests that in prehistoric hunter-gatherer societies, life expectancy at birth was much lower &ndash; at about 25 years &ndash; than it is today.

However, some people argue that this low figure is primarily due to high infant and child mortality.
If prehistoric people made it to adolescence, they often survived to old age.


Similar observations are made for modern hunter-gatherer societies: While mortality is significantly higher at the beginning of life, it decreases radically as soon as the first years have been survived.
A life span of 70 years then becomes nothing unusual.

## Back to the stone age?

These observations are sometimes invoked to make arguments about different lifestyles.

If hunter-gatherers often live to such a ripe old age despite a lack of modern health care, does that suggest that their lifestyle is particularly healthy?

In the end, could one even conclude that modern medicine is not doing much to make us live longer?


That the situation for complications at birth and in young years has improved is clear.
But what happens afterwards?
Perhaps the benefits that modern medicine brings us are offset by the increased risk of succumbing to so-called diseases of civilization?


## Survival graph

But before diving into such speculation, we should first think about how these data &ndash; low life expectancy at birth, high life expectancy *after surviving childhood* &ndash; come about.


<center>
```{r p2, echo=FALSE, out.width='60%'}
p2
```
</center>

People differ from birth in certain factors that are influenced by genes.
For example, some people are particularly susceptible to infections, others are more fortunate and have fitter immune systems.

We have summarized all such differences here under the label *intrinsic robustness*.

Now we are interested in how much the society we live in (traditional hunter-gatherer vs. modern) influences whether we live to see our 70th birthday &ndash; independent of the effects on survival to the 5th birthday.


```{r chain, echo=FALSE}
question("What is the role of \"Surviving until age 5\" in the subgraph with \"Intrinsic robustness\" and \"Type of society\"?",
  answer("Mediator"),
  answer("Confounder"),
  answer("Collider", correct = TRUE, message = "Correct &ndash; the two arrows both point into \"Surviving until age 5\""),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement())
```

##

If we calculate life expectancy for a person who has reached age 5, separately for the two types of society, then our analyses are conditioning on the variable "Surviving until age 5."
But this is a collider on the path between "Intrinsic Robustness" and "Type of Society."
Thus, our analyses lead to a non-causal correlation between intrinsic robustness and type of society.

The comparison of the two life expectancies conditional on survival to age 5 is thus a biased estimator for the direct effect of "type of society" on "survival into old age."

On a substantive level, this is actually quite intuitive. 
Anyone who survives a few years in a society with numerous risks to survival must be relatively robust by disposition.
Those who grow up in a society with few risks and good health care have good chances of survival, even if they are affected by certain potential health vulnerabilities.

The population of people over 5 in hunter-gatherer societies is thus quite different from the population of people over 5 in modern societies.
A naive comparison of these two populations mixes effects of the type of society on survival with spurious correlations that are induced by the "selection filter" of survival into childhood.

So from these data alone, we cannot yet draw any firm conclusions about the advantages or disadvantages of certain lifestyles for longevity.

An experiment in which we randomly assign children who have reached a certain age to grow up in a different type of society is of course only feasible as a thought experiment.
But we could try to approximate the outcome of such an experiment with available observational data.
However, to do so, we can't just compare different life expectancies -- we need to start to take additional third variables into account, such as the existence of certain potential health vulnerabilities.


## Outlook

We hope that we were able to provide you with some tools to critically question causal inferences in practice.
Here are a couple of helpful resources if you want to go into more depth:

Judea Pearl, Madelyn Glymour and Nicholas P. Jewell. [Causal Inference in Statistics: A Primer](http://bayes.cs.ucla.edu/PRIMER/). This book provides a more thorough introduction to the basics that we covered throughout this course.

Jonas Peters, Dominik Janzing and Bernhard Schölkopf. [Elements of Causal Inference: Foundations and Learning Algorithms*](https://mitpress.mit.edu/books/elements-causal-inference). You already met one of the authors, Jonas Peters, in one of the interviews. This book also covers how causal ideas can be exploited for classical machine learning problems.



Richard McElreath. [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/). You also already met Richard McElreath in one of the interviews. His book provides a more general introduction to Bayesian statistics, but the second edition also covers causal inference in some depth.


Ethan Bueno de Mesquita and Anthony Fowler. [Thinking Clearly with Data: A Guide to Quantitative Reasoning and Analysis](https://press.princeton.edu/books/paperback/9780691214351/thinking-clearly-with-data). This book also provides a great introduction to causal inference, albeit from a slightly different perspective. 

Various other books that each tackle the topic, each with their own disciplinary perspective:

Scott Cunningham. [Causal Inference: The Mixtape*](https://mixtape.scunning.com/).

Nick Huntington-Klein. [The Effect: An Introduction to Research Design and Causality*](https://theeffectbook.net/) 

Miguel A. Hernán and James M. Robins. [Causal Inference: What If*](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/).

*All books marked with a star are available online, for free.*

<br>

Of course, there is much to learn beyond the conceptual basics.
On the following page, we provide some overview over different aspects and branches that you might decide to dive into, depending on the applications you are interested in.

##

### Methods for third variable adjustment
In this course, you have learned that third variables should sometimes be included in analyses -- and sometimes not, depending on the role they play in the causal graph.
Such adjustment can be made in a variety of ways.
For example, in the course you saw that variables can be included as predictors in a linear regression model.
But other statistical approaches are also possible, such as splitting the sample (stratification) or calculating propensity scores (see interview with Dean Eckles on social contagion).
Machine learning methods are also applied for this purpose.

*Learn more*: 

- Stephen L. Morgan and Christopher Winship. [Counterfactuals and Causal Inference: Methods and Principles for Social Research](https://www.cambridge.org/core/books/counterfactuals-and-causal-inference/5CC81E6DF63C5E5A8B88F79D45E1D1B7).

### Natural Experiments
In this course, you learned about the magic of chance that makes randomized experiments such a useful tool for causal inference.
Between randomized experiments and "pure" observational data, there are also so-called natural experiments.
In these, you take advantage of the fact that in everyday life sometimes things are practically decided by chance.

You have already heard about a first example of a natural experiment in the interview with Anne Brenøe on the subject of the *effects of breastfeeding*: whether a pregnant woman gives birth during the week or on the weekend is in principle random, but can have an influence on whether and how long she will breastfeed after the birth.

In this domain, analysis are often conducted with the help of **instrumental variables**, using a **regression discontinuity** design, or with a **difference-in-difference** approach

Works in this area where honored with the 2021 Nobel Memorial Prize in Economic Sciences, awarded to David Card, Joshua Angrist and Guido Imbens.

How these methods can be used to address important questions has been summarized by the Swedish Academy of Sciences [here](https://www.nobelprize.org/uploads/2021/10/popular-economicsciencesprize2021-3.pdf).


*Learn more*:

- Thad Dunning. [Natural Experiments in the Social Sciences](https://www.cambridge.org/gb/academic/subjects/social-science-research-methods/qualitative-methods/natural-experiments-social-sciences-design-based-approach?format=PB&isbn=9781107698000).
- Joshua D. Angrist and Jörn-Steffen Pischke. [Mastering 'Metrics: The Path from Cause to Effect](http://www.masteringmetrics.com/).


### Causal Discovery
In this course, we have often assumed that the underlying causal graph is known a priori.
But what if this is not the case?
Then we have to move into the area of causal discovery, where the goal is to infer a plausible causal graph supported by the data.
In the last three interviews with Jakob Runge, Jonas Peters and Sebastian Weichwald, you have already gained a glimpse into this complex of topics.

*Learn more*: 

- Peter Spirtes, Clark Glymour and Richard Scheines. [Causation, Prediction, and Search](http://cognet.mit.edu/book/causation-prediction-and-search).

### Data Fusion
From a bird's eye view, there are many data sources that can be consulted to learn more about causes and effects.
In general, none of them is perfect.
Observational studies often suffer from unobserved confounders.
But in experiments, not all subjects always do what we want them to do, and sometimes we have to rely on other populations -- for example, in the initial stages of drug approval, on cell cultures and animal studies.
Lack of data and selective sampling further complicate the situation.
The idea of causal fusion is that we can still use all these data sources *in combination* to arrive at the best possible causal conclusions.

*Learn more*: 

- Paul Hünermund and Elias Bareinboim. [Causal Inference and Data-Fusion in Econometrics](https://arxiv.org/abs/1912.09104v2).


## AI Campus

[Back to course](https://learn.ki-campus.org/courses/b4f3bf71-74b1-48d8-a4c4-61aef5a808eb/launch)