---
title: "Module 12: Interrogating Data in Practice"
output: 
  learnr::tutorial:
    progressive: true
    css: "css/style.css"
runtime: shiny_prerendered
---

<a href="https://ki-campus.org/">
<img border="0" alt="KICampusLogo" src="images/KIcampusLogo.png" width="100" height="30" style="float: right">
</a>

```{r setup, include=FALSE}
library(ggplot2)
library(ggdag)
library(ggraph)
theme.fom <- theme_classic(22*1.04)
theme.fom <- theme.fom
theme_set(
  theme.fom  
)

# coordCof <- list(
#   x = c(coffee = 0, miscarriage = 2, nausea = 0.5, U = 1.5),
#   y = c(coffee = 1, miscarriage = 1, nausea = 0, U = 0))
# 
# dagCof <- dagify(coffee ~ nausea,
#                 nausea ~ U,
#                 miscarriage ~ U + coffee,
#                 coords = coordCof,
#                 exposure = "coffee",
#                 outcome = "miscarriage") 
# 
# p1 <- ggdag(dagCof, text_col = "blue", node = FALSE) + theme_dag_blank() 

p1 <- DiagrammeR::grViz("
digraph {
rankdir = LR;
ranksep = 0.7;
 graph []
 node [shape = circle fontcolor = black fontname = Poppins fontsize = 6 style = filled]
   A [label = 'Coffee consumption' fillcolor = '#0F710B' fontcolor = white]
   B [label = '  Miscarriage  ' fillcolor = '#0033cc' fontcolor = white]
   C [label = '    Nausea    ']
   U [label = '         U        ']
 edge [minlen = 2]
  A -> B      [penwidth = .2]
  C -> A      [penwidth = .2]
  U -> {B; C} [penwidth = .2]
{rank = same; A; C}
{rank = same; B; U}
}
")


# coordLif <- list(
#   x = c(robust = 0, society = 0, five = 1, seventy = 2),
#   y = c(robust = 2, society = 0, five = 1, seventy = 1))
# dagLif <- dagify(five ~ robust + society,
#                 seventy ~ five + robust + society,
#                 exposure = "society",
#                 outcome = "seventy",
#                 labels = c("robust" = "Intrinsic\n robustness",
#             "society" = "Type of society",
#             "five" = "Surviving until age 5",
#             "seventy" = "Surviving until age 70"),
#                 coords = coordLif)  
# p2 <- ggdag(dagLif, text = FALSE, text_col = "blue", use_labels = "label", label_col = "blue") + 
#   theme_dag_blank()

p2 <- DiagrammeR::grViz("
digraph {
rankdir = LR;
 graph []
 node [shape = circle fontcolor = black fontname = Poppins fontsize = 11 style = filled]
   A [label = 'Intrinsic Robustness']
   B [label = '  Type of Society  ' fillcolor = '#0F710B' fontcolor = white]
   C [label = '    Surviving until age 5    ']
   D [label = '    Surviving until age 70    ' fillcolor = '#0033cc' fontcolor = white]
 edge [minlen = 2]
   {A; B} -> {C; D} [penwidth = .5]
        C -> D      [penwidth = .5]
}
")


library(learnr)
library(mosaic)
```

## Learning objectives

In this module you will learn:

- what data interrogation can look like in practice;

- what else there is to learn about causal inference beyond the basics.


## Correlation and causality


Correlation does not imply causality &ndash; and no correlation does not imply no causality.

[Bueno de Mesquita und Fowler (2021)](https://press.princeton.edu/books/paperback/9780691214351/thinking-clearly-with-data) put it like this:

$$
Observed \, correlation = Causal\,effect + Bias + Noise
$$

We hope that this course with its examples has helped you think more clearly about systematic *bias* and how it can be addressed.

*Noise* arises from additional (random, unsystematic) sampling variation and is a topic that is covered in more depth in courses on statistics.

## The problem with simplified examples

In this course, you have learned how to define causal effects and how to use causal graphs to map assumptions and infer valid conclusions *under those assumptions*.

But all graphs you saw were highly simplified and contained only few variables.
Reality, of course, looks much more complex &ndash; graphs can contain hundreds of variables, including often ones that are hard to measure or even unobservable.

Even worse, in many situations, we simply do not know what the underlying causal graph looks like.


```{r unsicher, echo=FALSE}
question("Suppose we do not know the true underlying causal graph with certainty, and yet we want to infer causal effects from observational data. Can we still be fully confident that our inferences are correct?",
  answer("Yes."),
  answer("No.", correct = TRUE, message = "Uncertainty about the causal graph leads to uncertainty about whether our inferences are correct. For example, we often cannot rule out the possibility that additional unobserved confounders are biasing our results."),
  allow_retry = TRUE,
  correct = random_praise(),
  incorrect = random_encouragement()
)
```

## Perfect is the enemy of good

But that is no reason to throw in the towel!

Conclusions are always subject to certain uncertainties. 
Even if you know the underlying causal network perfectly well, random noise can still lead to wrong results. 
And even highly complex scientific models are always a simplified representation of reality.


***

***Note:*** In her book ["Idealization and the Aims of Science"](https://www.angelapotochnik.com/idealization.html), philosopher of science Angela Potochnik deals at length with the central role that simplifications play in science -- even in hard sciences like physics. 

***

Even if we do not know the full causal graph, knowledge of the fundamental causal structures helps us to critically question causal inferences and to identify possible biases.


## Example 1: Coffee and miscarriages

Observational studies report a correlation between coffee in pregnancy and miscarriages.
A causal effect is not necessarily implausible here: caffeine can cross the placenta in pregnant women.
That's why it's often recommended to avoid coffee (and other caffeinated beverages) altogether during pregnancy.
But is there really a causal effect that justifies this recommendation?

Coffee consumption during pregnancy depends on many factors.
For example, especially in the first trimester, many women suffer from nausea, which makes coffee a lot less enjoyable.

Furthermore, another line of studies suggests that nausea and vomiting in pregnancy are *negatively* correlated with miscarriage risk.
One possible explanation is that the nausea is caused by hormones that are abundant in a healthy pregnancy.


```{r kaffee, echo=FALSE}
question("What fundamental causal structure does this imply between coffee, nausea, and miscarriage?",
  answer("A chain"),
  answer("A fork", correct = TRUE, message = "Nausea influences coffee consumption, nausea correlates with miscarriage risk. Thus, nausea could be a confounder or at least on a confounding pathway where an unobserved variable (e.g., hormones) influences both nausea and miscarriage risk."),
  answer("An inverted fork"),
  allow_retry = TRUE,
  correct = random_praise(),
  incorrect = random_encouragement()
)
```

## Coffee graph

<center>
```{r p1, echo=FALSE, out.width="40%"}
p1
```
</center>

Studies that adjust for nausea as a variable on a potentially confounding pathway ($coffee \leftarrow nausea \leftarrow U \rightarrow miscarriage$) tend to find weaker associations between coffee consumption and miscarriage risk.

The idea that nausea is on a confounding pathway is also supported by the fact that studies overall find less consistent associations between miscarriage and consumption of other caffeinated beverages (e.g., tea or cola).
While these contain caffeine, they are often found to be less revolting for pregnant women suffering from nausea.

All things considered, the [American College of Obstetricians and Gynecologist (2020)](https://www.acog.org/clinical/clinical-guidance/committee-opinion/articles/2010/08/moderate-caffeine-consumption-during-pregnancy) concludes that moderate caffeine consumption (less than 200mg per day) does not appear to be a risk factor.
At this point in time, no firm conclusion can be drawn regarding larger doses of caffeine in pregnancy.

***

***Note:*** The connections between coffee, nausea, and miscarriages is discussed in more detail in the book "Expecting Better" by economist Emily Oster.

***


## Example 2: Life expectancy in hunter-gatherer societies

Here is an example that has already come up in the interview with Richard McElreath.

Consistent evidence suggests that in prehistoric hunter-gatherer societies, life expectancy at birth was much lower than it is today, at about 25 years.

However, some people argue that this low figure is primarily due to high infant and child mortality.
If prehistoric people made it to adolescence, they often survived to old age.


Similar observations are made for modern hunter-gatherer societies: While mortality is significantly higher at the beginning of life, it decreases radically as soon as the first years have been survived.
A life span of 70 years then becomes nothing unusual.

## Back to the stone age?

These observations are sometimes invoked to make arguments about different lifestyles.

If hunter-gatherers often live to such a ripe old age despite a lack of modern health care, does that suggest that their lifestyle is particularly healthy?

In the end, could one even conclude that modern medicine is not doing much to make us live longer?


That the situation for complications at birth and in young years has improved is clear.
But what happens afterwards?
Perhaps the benefits that modern medicine brings us are offset by the increased risk of succumbing to so-called diseases of civilization?


## Survival graph

But before diving into such speculation, we should first think about how these data &ndash; low life expectancy at birth, high life expectancy *after surviving childhood* &ndash; come about.


<center>
```{r p2, echo=FALSE, out.width='60%'}
p2
```
</center>

People differ from birth in certain factors that are influenced by genes.
For example, some people are particularly susceptible to infections, others are more fortunate and have fitter immune systems.

We have summarized all such differences here under the label *Intrinsic robustness*.

Now we are interested in how much the society we live in (traditional hunter-gatherer vs. modern) influences whether we live to see our 70th birthday &ndash; independent of the effects on survival to the 5th birthday.


```{r chain, echo=FALSE}
question("What is the role of \"Surviving until age 5\" in the subgraph with \"Intrinsic robustness\" and \"Type of society\"?",
  answer("Mediator"),
  answer("Confounder"),
  answer("Collider", correct = TRUE, message = "Correct &ndash; the two arrows both point into \"Surviving until age 5\""),
         allow_retry = TRUE,
         correct = random_praise(),
         incorrect = random_encouragement())
```

##

If we calculate life expectancy for a person who has reached age 5, separately for the two types of society, then our analyses are conditioning on the variable "Surviving until age 5."
But this is a collider on the path between "Intrinsic Robustness" and "Type of Society."
Thus, our analyses lead to a non-causal correlation between intrinsic robustness and type of society.

The comparison of the two life expectancies conditional on survival to age 5 is thus a biased estimator for the direct effect of "type of society" on "to 70 survival."

On a substantive level, this is actually quite intuitive. 
Anyone who survives a few years in a society with numerous risks to survival must be relatively robust by disposition.
Those who grow up in a society with few risks and good health care have good chances of survival, even if they are affected by certain potential health vulnerabilities.

The population of people over 5 in hunter-gatherer societies is thus "by design" quite different from the population of people over 5 in modern societies.
A naive comparison of these two populations mixes effects of the type of society on survival with spurious correlations that are induced by the "selection filter" of survival into childhood.

So from these data alone, we cannot yet draw any firm conclusions about the advantages or disadvantages of certain lifestyles for longevity.

An experiment in which we randomly assign children who have reached a certain age to grow up in a different type of society is of course only feasible as a thought experiment.
But we could try to approximate the outcome of such an experiment with available observational data.
However, to do so, we can't just compare different life expectancies -- we need to start to take additional third variables into account, such as the existince of certain potential health vulnerabilities.


## Outlook

We hope that we were able to provide you with some tools to critically question causal inferences in practice.

Von Judea Pearl, Madelyn Glymour und Nicholas P. Jewell gibt es das Buch [Causal Inference in Statistics: A Primer](http://bayes.cs.ucla.edu/PRIMER/), welches die hier vorgestellten Grundlagen ausführlicher behandelt. 
Jonas Peters (den Sie bereits aus dem Interview kennen) hat zusammen mit Dominik Janzing und Bernhard Schölkopf auch ein Buch geschrieben: [Elements of Causal Inference: Foundations and Learning Algorithms*](https://mitpress.mit.edu/books/elements-causal-inference).
Das Thema kausale Inferenz wird im Buch [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/) im 6. Kapitel der zweiten Auflage von Richard McElreath behandelt &ndash; auch ihn kennen Sie schon aus dem Interview.
Ethan Bueno de Mesquita und Anthony Fowler behandeln in ihrem Buch [Thinking Clearly with Data: A Guide to Quantitative Reasoning and Analysis](https://press.princeton.edu/books/paperback/9780691214351/thinking-clearly-with-data) auch das Thema Kausale Inferenz sehr gut &ndash; allerdings aus einem etwas anderen Blickwinkel.

Weitere Bücher aus unterschiedlichen Perspektiven sind z. B. [Causal Inference: The Mixtape*](https://mixtape.scunning.com/) von Scott Cunningham, [The Effect: An Introduction to Research Design and Causality*](https://theeffectbook.net/) von Nick Huntington-Klein oder [Causal Inference: What If*](https://www.hsph.harvard.edu/miguel-hernan/causal-inference-book/) von Hernán und Robins.

Die mit einem Sternchen markierten Titel sind online frei verfügbar.

<br>

Natürlich gibt es über die konzeptuellen Grundlagen hinaus noch viel zu lernen, beispielsweise in den auf den nächsten Seiten beschriebenen Themenbereichen.

##

### Methoden für die Adjustierung von Drittvariablen
In diesem Kurs haben Sie gelernt, dass Drittvariablen manchmal in Analysen berücksichtigt werden sollten -- und manchmal nicht, je nach der Rolle, die sie im kausalen Graphen spielen.
Eine solche Adjustierung kann auf unterschiedliche Arten vorgenommen werden.
Im Kurs haben Sie beispielsweise gesehen, dass Variablen als Prädiktoren in einem linearen Regressionsmodel aufgenommen werden können.
Aber auch andere statistische Vorgehensweisen sind möglich, zum Beispiel das Aufteilen der Stichprobe (Stratifizierung) oder die Berechnung von Propensity Scores (siehe Interview mit Dean Eckles zu sozialer Ansteckung).
Auch Methoden des maschinellen Lernens finden hier Anwendung.

*Lesetipp*: 

- Stephen L. Morgan und Christopher Winship, [Counterfactuals and Causal Inference: Methods and Principles for Social Research](https://www.cambridge.org/core/books/counterfactuals-and-causal-inference/5CC81E6DF63C5E5A8B88F79D45E1D1B7)

### Natürliche Experimente
In diesem Kurs haben Sie etwas über die Magie des Zufalls gelernt, die randomisierte Experimente zu so einem nützlichen Werkzeug in der Kausalinferenz macht.
Zwischen randomisierte Experimenten und "reinen" Beobachtungsdaten liegen die sogenannten natürlichen Experimente.
Hier macht man es sich zu Nutzen, dass im Alltag manchmal Dinge praktisch durch Zufall entschieden werden.

Ein erstes Beispiel für ein natürliches Experiment haben Sie schon im Interview mit Anne Brenøe zum Thema *Effekte des Stillens* kennengelernt: Ob eine Schwangere unter der Woche oder am Wochenende entbindet, ist im Prinzip zufällig, kann aber einen Einfluss darauf haben, ob und wie lange sie nach der Geburt stillen wird.

Zur Analyse können dabei häufig sogenannte **Instrumentvariablen** oder eine **Regressions-Diskontinuitäts-Analyse** angewendet werden. Oder es wird die **Differenz-von-Differenzen** betrachtet. 

Für Arbeiten in diesem Bereich wurde übrigens im Jahre 2021 der Alfred-Nobel-Gedächtnispreis für Wirtschaftswissenschaften an David Card, Joshua Angrist und Guido Imbens verliehen! Herzlichen Glückwunsch! <br>

Wie diese Methoden helfen wichtige Fragen zu beantworten hat die Schwedische Akademie der Wissenschaften [hier](https://www.nobelprize.org/uploads/2021/10/popular-economicsciencesprize2021-3.pdf) beschrieben.


*Lesetipps*:

- Thad Dunning, [Natural Experiments in the Social Sciences](https://www.cambridge.org/gb/academic/subjects/social-science-research-methods/qualitative-methods/natural-experiments-social-sciences-design-based-approach?format=PB&isbn=9781107698000)
- Joshua D. Angrist und Jörn-Steffen Pischke, [Mastering 'Metrics: The Path from Cause to Effect](http://www.masteringmetrics.com/)


### Causal Discovery
In diesem Kurs sind wir oft davon ausgegangen, dass der zugrundeliegende kausale Graph im Prinzip bekannt ist.
Was aber, wenn das nicht der Fall ist?
Dann bewegen wir uns in den Bereich Causal Discovery, in dem es das Ziel ist, unterstützt durch Daten einen plausiblen kausalen Graphen herzuleiten.
In den letzten drei Interviews mit Jakob Runge, Jonas Peters und Sebastian Weichwald haben Sie schon einen ersten Einblick in den Themenkomplex bekommen.

*Lesetipp*: 

- Peter Spirtes, Clark Glymour und Richard Scheines, [Causation, Prediction, and Search](http://cognet.mit.edu/book/causation-prediction-and-search)

### Data Fusion
Aus der Vogelperspektive betrachtet gibt es viele Datenquellen, die herangezogen werden können, um mehr über Ursachen und Effekte zu lernen.
In der Regel ist keine davon perfekt.
Beobachtungsstudien leiden oft unter unbeobachteten Confoundern; in Experimenten machen nicht immer alle Personen das, was wir uns wünschen, und manchmal müssen wir auf andere Populationen zurückgreifen -- zum Beispiel in den initialen Stadien der Medikamentenzulassung auf Zellkulturen und Tierversuche.
Fehlende Daten und selektive Stichproben verkomplizieren die Situation weiter.
Die Idee der Causal Fusion ist, dass wir trotzdem all diese Datenquellen *in Kombination* nutzen können, um zu den bestmöglichen kausalen Schlußfolgerungen zu gelangen.

*Lesetipp*: 

- Paul Hünermund und Elias Bareinboim, [Causal Inference and Data-Fusion in Econometrics](https://arxiv.org/abs/1912.09104v2)


## Hinweis

<red> **Dieser Kurs ist aktuell noch in der Entwicklung!** </red>

Bitte melden Sie Fehler, Unklarheiten und Verbesserungsvorschläge [hier](https://github.com/luebby/WWWEKI/issues).

Das Vorhaben *Was, wie, warum? Einstiegskurs Kausale Inferenz (WWWEKI)* wird mit Mitteln des Bundesministeriums für Bildung und Forschung unter dem Förderkennzeichen 16DHBQP040 gefördert.


![](images/csm_Logo-BMBF.jpg)